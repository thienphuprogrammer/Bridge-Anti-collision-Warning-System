{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T10:13:48.998193100Z",
     "start_time": "2024-07-20T10:13:36.122777400Z"
    }
   },
   "id": "205ee361c523b171",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "yolo = YOLO(\"../yolov8m.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T10:13:49.299345600Z",
     "start_time": "2024-07-20T10:13:49.002190800Z"
    }
   },
   "id": "f0e3221de94d1a7b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x384 3 persons, 2 bottles, 2 cups, 3 chairs, 1 dining table, 3 laptops, 1456.0ms\n",
      "Speed: 5.0ms preprocess, 1456.0ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('../image/img_4.png')\n",
    "res = yolo(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T10:13:57.151670500Z",
     "start_time": "2024-07-20T10:13:49.303346100Z"
    }
   },
   "id": "715eaf077674df33",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([60., 41., 63., 63.,  0.,  0.,  0., 56., 39., 41., 56., 56., 39., 63.])\n"
     ]
    }
   ],
   "source": [
    "objects = res[0].boxes\n",
    "labels = objects.cls\n",
    "print(labels)\n",
    "objects = objects[labels == 41]\n",
    "loc = objects.xyxy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T10:13:57.208671200Z",
     "start_time": "2024-07-20T10:13:57.153667100Z"
    }
   },
   "id": "23c9dd49032a4f0b",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loc = np.array(loc).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T10:13:57.209667900Z",
     "start_time": "2024-07-20T10:13:57.184669400Z"
    }
   },
   "id": "e7b5fe1f9666b093",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[289, 668, 460, 873],\n       [665, 594, 719, 829]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T10:13:57.307668200Z",
     "start_time": "2024-07-20T10:13:57.207665800Z"
    }
   },
   "id": "9136c50712357883",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for x_min, y_min, x_max, y_max in loc:\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "    \n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T10:14:20.494839900Z",
     "start_time": "2024-07-20T10:13:57.230667800Z"
    }
   },
   "id": "2aa50e0a71de846e",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x384 4 persons, 1 cup, 2 chairs, 1 dining table, 2 laptops, 3284.1ms\n",
      "Speed: 102.0ms preprocess, 3284.1ms inference, 70.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 4 persons, 1 bottle, 1 cup, 1 chair, 1 dining table, 2 laptops, 1779.3ms\n",
      "Speed: 6.0ms preprocess, 1779.3ms inference, 20.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 4 persons, 1 cup, 1 chair, 1 dining table, 2 laptops, 1463.0ms\n",
      "Speed: 3.0ms preprocess, 1463.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 4 persons, 1 cup, 1 dining table, 2 laptops, 1284.0ms\n",
      "Speed: 4.0ms preprocess, 1284.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 4 persons, 1 cup, 1 chair, 1 dining table, 2 laptops, 1202.0ms\n",
      "Speed: 3.0ms preprocess, 1202.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 4 persons, 1 cup, 1 chair, 1 dining table, 2 laptops, 1275.0ms\n",
      "Speed: 5.0ms preprocess, 1275.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 5 persons, 1 cup, 1 potted plant, 2 dining tables, 2 laptops, 1121.0ms\n",
      "Speed: 5.0ms preprocess, 1121.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 4 persons, 1 cup, 1 chair, 2 dining tables, 2 laptops, 1453.0ms\n",
      "Speed: 4.0ms preprocess, 1453.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 4 persons, 1 cup, 2 dining tables, 2 laptops, 1401.0ms\n",
      "Speed: 4.0ms preprocess, 1401.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 4 persons, 1 bottle, 1 cup, 1 chair, 1 dining table, 2 laptops, 1474.0ms\n",
      "Speed: 4.0ms preprocess, 1474.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 3 persons, 1 bottle, 1 cup, 1 chair, 1 dining table, 2 laptops, 1203.0ms\n",
      "Speed: 3.0ms preprocess, 1203.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 3 persons, 1 cup, 1 chair, 1 dining table, 2 laptops, 1292.0ms\n",
      "Speed: 4.0ms preprocess, 1292.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 3 persons, 1 cup, 1 chair, 1 dining table, 2 laptops, 1139.0ms\n",
      "Speed: 3.0ms preprocess, 1139.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 3 persons, 1 cup, 1 chair, 1 dining table, 2 laptops, 1290.0ms\n",
      "Speed: 3.0ms preprocess, 1290.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 3 persons, 1 cup, 2 chairs, 1 dining table, 2 laptops, 1812.0ms\n",
      "Speed: 5.0ms preprocess, 1812.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 3 persons, 1 bottle, 1 cup, 2 chairs, 1 dining table, 1 laptop, 1313.0ms\n",
      "Speed: 5.0ms preprocess, 1313.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 3 persons, 1 bottle, 1 cup, 2 chairs, 1 dining table, 2 laptops, 1167.0ms\n",
      "Speed: 2.9ms preprocess, 1167.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 3 persons, 1 bottle, 1 cup, 2 chairs, 1 dining table, 2 laptops, 1181.0ms\n",
      "Speed: 4.0ms preprocess, 1181.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 3 persons, 1 cup, 2 chairs, 1 potted plant, 1 dining table, 2 laptops, 1111.0ms\n",
      "Speed: 6.0ms preprocess, 1111.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 persons, 1 cup, 4 chairs, 1 potted plant, 1 dining table, 2 laptops, 1164.0ms\n",
      "Speed: 3.0ms preprocess, 1164.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "0: 640x384 2 persons, 1 cup, 3 chairs, 1 potted plant, 1 dining table, 2 laptops, 1116.0ms\n",
      "Speed: 4.0ms preprocess, 1116.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('../image/5651690126911.mp4')\n",
    "\n",
    "if not cap.isOpened(): \n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Get the frame rate of the video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_interval = int(fps * 0.5)  # 500 ms interval\n",
    "\n",
    "list_points = []\n",
    "frame_count = 0\n",
    "\n",
    "# Read until video is completed\n",
    "while cap.isOpened():\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        if frame_count % frame_interval == 0:\n",
    "            result = yolo(frame)\n",
    "            objects = result[0].boxes\n",
    "            labels = objects.cls\n",
    "            objects = objects[labels == 41]\n",
    "            loc = objects.xyxy\n",
    "            loc = np.array(loc).astype(int)\n",
    "            list_points.append(loc)\n",
    "            for x_min, y_min, x_max, y_max in loc:\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Frame', frame)\n",
    "        \n",
    "        # Press Q on keyboard to exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T10:53:31.914756800Z",
     "start_time": "2024-07-20T10:52:50.645046900Z"
    }
   },
   "id": "a58977d555cb6ead",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[197, 483, 314, 631]]), array([[200, 495, 314, 643]]), array([[199, 533, 316, 683]]), array([[197, 549, 316, 699]]), array([[196, 552, 319, 711]]), array([[196, 554, 324, 720]]), array([[193, 553, 326, 730]]), array([[189, 555, 327, 745]]), array([[180, 561, 329, 758]]), array([[176, 564, 330, 771]]), array([[170, 566, 332, 786]]), array([[171, 569, 339, 795]]), array([[168, 573, 341, 802]]), array([[162, 579, 345, 827]]), array([[153, 584, 343, 842]]), array([[153, 565, 347, 838]]), array([[142, 542, 349, 809]]), array([[137, 544, 359, 830]]), array([[134, 545, 392, 845]]), array([[130, 535, 402, 840]]), array([[131, 530, 397, 819]])]\n"
     ]
    }
   ],
   "source": [
    "print(list_points)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-20T10:53:53.490457600Z",
     "start_time": "2024-07-20T10:53:53.434447800Z"
    }
   },
   "id": "2bede58098d06ce1",
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
